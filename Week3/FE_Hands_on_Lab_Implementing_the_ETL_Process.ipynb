{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falawar7/AAI_634O/blob/main/Week3/FE_Hands_on_Lab_Implementing_the_ETL_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on Lab: Implementing the ETL (Extract, Transform, Load) Process**"
      ],
      "metadata": {
        "id": "MwRtqhfoEmJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "In this hands-on lab, students will learn how to implement the fundamental steps of the ETL process by extracting data from multiple sources, transforming the data, and loading it into a database. Students will use Python along with libraries such as Pandas for data transformation and PyMongo for loading the data into a MongoDB database.\n",
        "\n",
        "By the end of this lab, students will be able to:\n",
        "\n",
        "* Extract data from different sources (CSV and API).\n",
        "* Clean, transform, and validate the data.\n",
        "* Load the transformed data into MongoDB.\n",
        "* Automate the ETL process by building a reusable pipeline."
      ],
      "metadata": {
        "id": "_flGWYZjEygA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-requisites:**\n",
        "\n",
        "* Basic knowledge of Python.\n",
        "* MongoDB Atlas account (or a local MongoDB instance).\n",
        "* Install the required Python libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "WNqvAT4rFKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this Lab:**\n",
        "\n",
        "You are tasked with creating an ETL pipeline for a fictitious retail company. You will extract product and sales data from different sources (a CSV file and a REST API), transform the data by cleaning and standardizing it, and load the transformed data into MongoDB for further analysis."
      ],
      "metadata": {
        "id": "Af48YJb-FwIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Extract Data**\n",
        "\n",
        "**1.1. Extract Product Data from a CSV File**\n",
        "\n",
        "Create a CSV file named ***products.csv*** with the following data:\n",
        "\n",
        "product_id,product_name,category,price\n",
        "\n",
        "1001,Laptop,Electronics,1200\n",
        "\n",
        "1002,Smartphone,Electronics,800\n",
        "\n",
        "1003,Chair,Furniture,150"
      ],
      "metadata": {
        "id": "HdEXdoqcF4wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Python and Pandas to extract the product data from this CSV file."
      ],
      "metadata": {
        "id": "3C7Wvw-WGM9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract data from the CSV file\n",
        "products_df = pd.read_csv('https://raw.githubusercontent.com/falawar7/AAI_634O/refs/heads/main/Week3/products.csv')\n",
        "print(\"Extracted Product Data:\")\n",
        "print(products_df)"
      ],
      "metadata": {
        "id": "1e-U7ChnGOSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2f2f2e-493c-40f2-e48f-03dbd1ca8af7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Product Data:\n",
            "   product_id product_name     category  price\n",
            "0        1001       Laptop  Electronics   1200\n",
            "1        1002   Smartphone  Electronics    800\n",
            "2        1003        Chair    Furniture    150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Extract Sales Data from a REST API**\n",
        "\n",
        "For the sales data, we will simulate an API response using a dictionary. In a real-world scenario, you would use the requests library to fetch data from an API."
      ],
      "metadata": {
        "id": "ftylwwhwGRT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Simulated API response (in a real scenario, use requests.get(URL).json())\n",
        "sales_data = [\n",
        "    {\"sale_id\": \"S001\", \"product_id\": \"1001\", \"quantity\": 2, \"total\": 2400},\n",
        "    {\"sale_id\": \"S002\", \"product_id\": \"1002\", \"quantity\": 1, \"total\": 800},\n",
        "    {\"sale_id\": \"S003\", \"product_id\": \"1003\", \"quantity\": 4, \"total\": 600}\n",
        "]\n",
        "\n",
        "print(\"Extracted Sales Data:\")\n",
        "print(sales_data)\n"
      ],
      "metadata": {
        "id": "mcwhIOGxGXok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e505e5ba-936f-4926-de73-8233fc3843b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Sales Data:\n",
            "[{'sale_id': 'S001', 'product_id': '1001', 'quantity': 2, 'total': 2400}, {'sale_id': 'S002', 'product_id': '1002', 'quantity': 1, 'total': 800}, {'sale_id': 'S003', 'product_id': '1003', 'quantity': 4, 'total': 600}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Transform Data**\n",
        "\n",
        "**2.1. Clean and Standardize the Product Data**\n",
        "\n",
        "Use Pandas to clean and transform the product data. For this example, let's assume you need to ensure the price field is numeric and filter out products that are too expensive."
      ],
      "metadata": {
        "id": "QARgvzg4Gaem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_dMe0MFcfPp",
        "outputId": "4262f128-b1ab-4922-ea37-0cf9c65e92df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sale_id     3 non-null      object\n",
            " 1   product_id  3 non-null      object\n",
            " 2   quantity    3 non-null      int64 \n",
            " 3   total       3 non-null      int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 228.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#need to Change product_id from obeject to int\n",
        "sales_df['product_id'] = pd.to_numeric(sales_df['product_id'])"
      ],
      "metadata": {
        "id": "iwNnctv8c7C8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKndbKVOdIm-",
        "outputId": "1f8ea1e4-a3af-42fa-8215-e4abaa70c92a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sale_id     3 non-null      object\n",
            " 1   product_id  3 non-null      int64 \n",
            " 2   quantity    3 non-null      int64 \n",
            " 3   total       3 non-null      int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 228.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products_df['product_id'] = pd.to_numeric(products_df['product_id'])"
      ],
      "metadata": {
        "id": "Yx_Z81bzd9V_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvRwz5CUeCls",
        "outputId": "9d633c55-d431-4c46-e078-84e59c881f2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   product_id    3 non-null      int64 \n",
            " 1   product_name  3 non-null      object\n",
            " 2   category      3 non-null      object\n",
            " 3   price         3 non-null      int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 228.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Enrich the Sales Data**\n",
        "\n",
        "For the sales data, we'll perform a simple enrichment by adding the product_name to each sale by joining the sales_data and products_df on the product_id."
      ],
      "metadata": {
        "id": "XWTlr7q-GiMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sales_data to a DataFrame\n",
        "sales_df = pd.DataFrame(sales_data)\n",
        "# Convert 'product_id' to numeric before merging\n",
        "sales_df['product_id'] = pd.to_numeric(sales_df['product_id'])\n",
        "products_df['product_id'] = pd.to_numeric(products_df['product_id'])\n",
        "\n",
        "# Join sales data with product data to add product_name\n",
        "sales_df = pd.merge(sales_df, products_df[['product_id', 'product_name']], on='product_id', how='left')\n",
        "print(\"Enriched Sales Data:\")\n",
        "print(sales_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPQrKmOTGf8M",
        "outputId": "b4ab1d70-13a0-4dd1-e4e7-2ac241d4e954"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enriched Sales Data:\n",
            "  sale_id  product_id  quantity  total product_name\n",
            "0    S001        1001         2   2400       Laptop\n",
            "1    S002        1002         1    800   Smartphone\n",
            "2    S003        1003         4    600        Chair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Load Data into MongoDB**\n",
        "\n",
        "Now that the data is transformed and cleaned, load the product and sales data into MongoDB.\n",
        "\n",
        "**3.1. Connect to MongoDB**\n",
        "\n",
        "Ensure you have MongoDB running locally or use MongoDB Atlas. Connect to MongoDB using PyMongo."
      ],
      "metadata": {
        "id": "N_J9biezGzQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install \"pymongo[srv]==3.11\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nchxvSb3fYYw",
        "outputId": "be93cdff-1adc-4869-fdeb-8189d81772b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo==3.11 (from pymongo[srv]==3.11)\n",
            "  Downloading pymongo-3.11.0.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.7/771.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython<2.0.0,>=1.16.0 (from pymongo[srv]==3.11)\n",
            "  Downloading dnspython-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pymongo\n",
            "  Building wheel for pymongo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymongo: filename=pymongo-3.11.0-cp311-cp311-linux_x86_64.whl size=495608 sha256=7d527681011ac9ca78899c336cca82cde2194b88c347d8f66b087fb09354a0cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/00/27/6d27c275881078538e7cd04e595f2f3a1f14b1ef9e32e40583\n",
            "Successfully built pymongo\n",
            "Installing collected packages: pymongo, dnspython\n",
            "Successfully installed dnspython-1.16.0 pymongo-3.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Connect to MongoDB (replace <username> and <password> with your MongoDB Atlas credentials)\n",
        "client = MongoClient(\"mongodb+srv://faysalelawar:pb6LB2kBPQ5Be5vN@dataengineeringcluster.61mrj.mongodb.net/?retryWrites=true&w=majority&appName=DataEngineeringCluster\")\n",
        "db = client['retail_db']\n"
      ],
      "metadata": {
        "id": "J-WpayvQG3NP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Load Product Data**\n",
        "\n",
        "Insert the transformed product data into the MongoDB products collection."
      ],
      "metadata": {
        "id": "KdbvO_ynG5W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "product_records = products_df.to_dict(orient='records')\n",
        "db.products.insert_many(product_records)\n",
        "print(\"Loaded Product Data into MongoDB\")\n"
      ],
      "metadata": {
        "id": "yFPviZ0jG-hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac8c937-c405-41c3-cd6d-729f4da2f780"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Product Data into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Load Sales Data**\n",
        "\n",
        "Insert the enriched sales data into the MongoDB sales collection."
      ],
      "metadata": {
        "id": "RcPF_GfEHBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "sales_records = sales_df.to_dict(orient='records')\n",
        "db.sales.insert_many(sales_records)\n",
        "print(\"Loaded Sales Data into MongoDB\")\n"
      ],
      "metadata": {
        "id": "xGqJWM2sHHSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79133486-3148-4cf4-94dd-70e8eadc0537"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Sales Data into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Automate the ETL Process**\n",
        "\n",
        "To make the ETL process reusable, wrap the steps into functions and run the ETL pipeline from start to finish."
      ],
      "metadata": {
        "id": "0w-Iu3KuHKGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_products():\n",
        "    products_df = pd.read_csv('https://raw.githubusercontent.com/falawar7/AAI_634O/refs/heads/main/Week3/products.csv')\n",
        "    # Convert 'product_id' to numeric in products_df\n",
        "    products_df['product_id'] = pd.to_numeric(products_df['product_id'])\n",
        "    return products_df\n",
        "\n",
        "def extract_sales():\n",
        "    sales_df = pd.DataFrame(sales_data)\n",
        "    # Convert 'product_id' to numeric in sales_df\n",
        "    sales_df['product_id'] = pd.to_numeric(sales_df['product_id'])\n",
        "    return sales_df\n",
        "\n",
        "def transform_products(products_df):\n",
        "    products_df['price'] = pd.to_numeric(products_df['price'], errors='coerce')\n",
        "    return products_df[products_df['price'] < 1000]\n",
        "\n",
        "def transform_sales(sales_df, products_df):\n",
        "    return pd.merge(sales_df, products_df[['product_id', 'product_name']], on='product_id', how='left')\n",
        "\n",
        "def load_data(products_df, sales_df):\n",
        "    db.products.insert_many(products_df.to_dict(orient='records'))\n",
        "    db.sales.insert_many(sales_df.to_dict(orient='records'))\n",
        "\n",
        "# Run the ETL pipeline\n",
        "products_df = extract_products()\n",
        "sales_df = extract_sales()\n",
        "transformed_products_df = transform_products(products_df)\n",
        "transformed_sales_df = transform_sales(sales_df, products_df)\n",
        "load_data(transformed_products_df, transformed_sales_df)\n",
        "print(\"ETL Process Completed!\")"
      ],
      "metadata": {
        "id": "p-h6IeqiHRIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5e7898-8354-450d-d70e-27ecc9dfd5b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETL Process Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "This hands-on lab provides a comprehensive introduction to the ETL process, from extracting raw data from multiple sources, transforming it for quality and consistency, and finally loading it into MongoDB."
      ],
      "metadata": {
        "id": "IJ2xNTfeEjAk"
      }
    }
  ]
}